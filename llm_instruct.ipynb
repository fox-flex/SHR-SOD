{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6694ff1-2e12-4efe-bc46-8575c60e4ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-system/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:114: UserWarning: alibi or rope is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi or rope is turned on, setting `learned_pos_emb` to `False.`')\n",
      "/home/ubuntu-system/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bb114eae4a42bab2cd8fdf8ddee259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f283674daed5420987b3a06416d3d3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e805747b6ed4eefa84dc111f585123e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1c3130f52148a9992004dd60a6d011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4341fb5570f4894a2ff0bc8a6f8ddb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "name = 'mosaicml/mpt-7b-instruct'\n",
    "device = 'cuda:0'\n",
    "config = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True)\n",
    "config.attn_config['attn_impl'] = 'triton'\n",
    "config.init_device = device # For fast initialization directly on GPU!\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "  name,\n",
    "  config=config,\n",
    "  torch_dtype=torch.bfloat16, # Load model weights in bfloat16\n",
    "  trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355c78d6-8218-486c-b771-a472c978f197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965d6f6059ae45158e2b7fb4edcb2cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e46034b69e418ba375deb4f232b791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea808c4781d4ea892814efd7a6e88b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/457k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca9b561385a4b97b6b77e19b1cac34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c5edb3d9104b00ab98b2407a13aa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f48719ac-d326-4fc9-826c-327405600f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\" Try #0 \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A fox roams through a dense pine forest, running across fallen branches and leaping from mound to mound. Beneath the shade of leaves and trunks, the fox moves confidently, glancing alertly from side to side. A lush forest scene rendered with warm pastel hues, highlighted by a soft, foggy atmosphere. From above, light filters through the trees and highlights the fox as it darts through the landscape. A painterly, dream-like feeling emphasized by the glowing colors and ethereal atmosphere, accentuated by the playful movement and expressive gestures.\n",
      "\n",
      "Dense pine forest landscape of glowing trees and trunks, rendered in warm pastel hues and detailed with playful movement and expressive gestures, accented by a soft, ethereal atmosphere. A fox roams the foreground, highlighted from above by dappled light filtering through trees.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\"\" Try #1 \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fox in a dense pine forest rendered in a style of 35mm film grain and a surreal, otherworldly color palette.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\"\" Try #2 \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may not know it, but the fox is a very loyal animal that loves people more than its own family! As long as you respect him for what he really is, you have his unconditional admiration.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\"\" Try #3 \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt is: \n",
      "Image of the fox.\n",
      "This prompt has been written in response to your one-sentence story: \"A fox is a cute animal in a green forest.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\"\" Try #4 \"\"\"\n",
      "Here is a list of stable diffusion prompts:\n",
      "\n",
      "â€¢ \"The noble fox stalks the forest trail and pauses before leaping onto the low branch of a spanish oak. Rendered in a hyper-realistic watercolor style, the fox's fur is intricately detailed and appears delicate as it peers into the forest around it. The background scenery is equally rich, consisting of dense pine forest, misty morning fog, and distant hills. Small white flowers bloom along the forest floor, providing a delicate contrast to the fox's sleek brown fur. The background scene also depicts the fox's environment - forest animals and other natural elements fill the landscape, creating a vivid and realistic scene. The fox's expressive eyes and playful stance make this image a perfect example of a Stable diffusion prompt!\"\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device=device)\n",
    "diffusion_prompt = \"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "You are an excellent Stable diffusion prompt writer. Given a one-sentence story, you can write a Stable diffusion prompt.\n",
    "\n",
    "Instructions for writing a Stable diffusion prompt with a one-sentence story:\n",
    "\n",
    "â€¢ Use specific descriptors based on the one-sentence story details (e.g., \"dense pine forest\" instead of \"forest\").\n",
    "â€¢ Detail objects mentioned in the one-sentence story (e.g., \"ancient leather-bound book\" instead of \"book\").\n",
    "â€¢ Highlight emotions conveyed in the one-sentence story (e.g., \"melancholic,\" \"joyful\").\n",
    "â€¢ Choose a visual style, such as \"35mm film,\" \"cinematic,\" \"watercolor\", \"oil painting\", \"3D art\".\n",
    "â€¢ Reference an artist or artistic style that aligns with the one-sentence story vibe.\n",
    "â€¢ Do not write any additional information to the prompt. Only one single prompt covered in \".\n",
    "\n",
    "Examples of Stable diffusion prompts:\n",
    "\n",
    "â€¢ \"Macie Grey in a Victorian dress, exploring a luminous garden with glowing plants and mystical creatures, rendered in a dreamy watercolor style with soft pastel hues.\"\n",
    "â€¢ \"Mark Hamel as an astronaut in a futuristic suit, examining an ancient monolith amidst ruins on an alien planet, captured with a 35mm film grain effect and a surreal, otherworldly color palette.\"\n",
    "â€¢ \"Baby shark with a painted face on an old wall, in the style of hyper-realistic sculptures, fragmented figures, distressed materials, tiled walls of light grays, cracked, rococoâ€”inspired art\"\n",
    "â€¢ \"Award-winning cinematic bioluminescent oil creature design in gold, vibrant holographic gradient blue and silver colored scheme, in the style 3d hydroâ€Šâ€”â€Šdrip venom character, ray tracing reflection, prismatic lighting, realistic texture detail, vibrant electric flames coursing through oil\"\n",
    "â€¢ \"Pope Francis wearing leather jacket is a DJ in a nightclub, mixing live on stage, giant mixing table, 4k resolution, a masterpiece\"\n",
    "â€¢ \"Kanye West in medieval armor, standing on a cliff's edge, watching a dragon soar from misty mountains, depicted in a Renaissance painting style with dramatic chiaroscuro lighting.\"\n",
    "â€¢ \"A trench-coated Dick Tracy, silhouette against neon noir streets, searching for elusive clues of a jewel thief, visualized in a vibrant neon noir style with rain-soaked streets reflecting the city's lights.\"\n",
    "\n",
    "One-sentence story: {instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "def predict(text):\n",
    "    prompt = diffusion_prompt.format(instruction=text)\n",
    "\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        res = pipe(\n",
    "            prompt,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            use_cache=True\n",
    "        )\n",
    "    res = res[0]['generated_text']\n",
    "    res = res[len(prompt):]\n",
    "    return res\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\"\"\" Try #{i} \"\"\"')\n",
    "    my_text = 'Image of the fox.'\n",
    "    res = predict(my_text)\n",
    "    print(res)\n",
    "    print('\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
